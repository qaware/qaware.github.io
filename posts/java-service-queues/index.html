<!doctype html><html lang=en><head><title>Don't Crack Under Pressure: Java Microservices and the Battle for Stability Under High Load - QAware | Software Engineering Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=yes"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=description content="Explore the challenges of Java microservices under high load conditions."><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Don't Crack Under Pressure: Java Microservices and the Battle for Stability Under High Load"><meta property="og:description" content="Explore the challenges of Java microservices under high load conditions."><meta property="og:url" content="https://blog.qaware.de/posts/java-service-queues/"><meta property="og:image" content="https://blog.qaware.de/images/java-service-queues/connections.png"><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><link rel=apple-touch-icon sizes=57x57 href=/apple-icon-57x57.png><link rel=apple-touch-icon sizes=60x60 href=/apple-icon-60x60.png><link rel=apple-touch-icon sizes=72x72 href=/apple-icon-72x72.png><link rel=apple-touch-icon sizes=76x76 href=/apple-icon-76x76.png><link rel=apple-touch-icon sizes=114x114 href=/apple-icon-114x114.png><link rel=apple-touch-icon sizes=120x120 href=/apple-icon-120x120.png><link rel=apple-touch-icon sizes=144x144 href=/apple-icon-144x144.png><link rel=apple-touch-icon sizes=152x152 href=/apple-icon-152x152.png><link rel=apple-touch-icon sizes=180x180 href=/apple-icon-180x180.png><link rel=icon type=image/png sizes=192x192 href=/android-icon-192x192.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=96x96 href=/favicon-96x96.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json crossorigin=use-credentials><link rel=icon href=/QAware_Logo_Icon_RGB_Petrol.svg type=image/svg+xml><meta name=msapplication-TileColor content="#ffffff"><meta name=msapplication-TileImage content="/ms-icon-144x144.png"><meta name=theme-color content="#ffffff"><link rel=canonical href=https://blog.qaware.de/posts/java-service-queues/><link rel=stylesheet href=https://blog.qaware.de/css/main.f210fa2882010d9f688c05dc3107f23bd9a95efa7a2a87e4024d0afbef4b93a346598e97380da3c9809d24ad136fdc4909cffe6f586c4f32a497e73f23b40e1a.css integrity='sha512-8hD6KIIBDZ9ojAXcMQfyO9mpXvp6KofkAk0K++9Lk6NGWY6XOA2jyYCdJK0Tb9xJCc/+b1hsTzKkl+c/I7QOGg==' title=templateStyle><script id=Cookiebot src=https://consent.cookiebot.com/uc.js data-cbid=4e938949-aa56-465e-9c2a-175bb6c31d81 data-blockingmode=auto type=text/javascript></script></head><body><header><div id=main-header><a href=/ id=main-header-logo><img src=/images/icons/logo_qaware.svg alt=QAware id=main-header-logo-img></a><div id=main-header-nav-items-container><nav id=main-nav><ul class=main-nav-menu><li class=main-nav-menu><a href=https://blog.qaware.de/ class="main-nav-menu nav-item">Posts</a><ul class=main-nav-sub-menu><li class=main-nav-sub-menu><a href=https://blog.qaware.de/tags/ class="main-nav-sub-menu nav-item">Tags</a></li><li class=main-nav-sub-menu><a href=https://blog.qaware.de/posts/ class="main-nav-sub-menu nav-item">Archive</a></li></ul></li><li class=main-nav-menu><a href=https://blog.qaware.de/ class="main-nav-menu nav-item">Resources</a><ul class=main-nav-sub-menu><li class=main-nav-sub-menu><a href=https://www.github.com/qaware class=main-nav-sub-menu>GitHub</a></li><li class=main-nav-sub-menu><a href=https://de.slideshare.net/QAware class=main-nav-sub-menu>SlideShare</a></li><li class=main-nav-sub-menu><a href=https://www.youtube.com/user/QAwareGmbH class=main-nav-sub-menu>YouTube</a></li><li class=main-nav-sub-menu><a href=https://www.meetup.com/de-DE/Cloud-Native-Night class=main-nav-sub-menu>Meetup Mainz</a></li><li class=main-nav-sub-menu><a href=https://www.meetup.com/de-DE/cloud-native-muc/ class=main-nav-sub-menu>Meetup Munich</a></li></ul></li><li class=main-nav-menu><a href=https://www.qaware.de class=main-nav-menu>Company</a><ul class=main-nav-sub-menu><li class=main-nav-sub-menu><a href=https://www.qaware.de class=main-nav-sub-menu>Website</a></li><li class=main-nav-sub-menu><a href=https://twitter.com/qaware class=main-nav-sub-menu>Twitter</a></li><li class=main-nav-sub-menu><a href=http://www.linkedin.com/company/qaware-gmbh class=main-nav-sub-menu>Linkedin</a></li><li class=main-nav-sub-menu><a href=http://www.xing.com/companies/qawaregmbh class=main-nav-sub-menu>Xing</a></li><li class=main-nav-sub-menu><a href=http://www.kununu.com/qaware class=main-nav-sub-menu>Kununu</a></li></ul></li><li class=main-nav-menu><a href=https://www.qaware.de/kontakt class=main-nav-menu>Contact</a></li></ul></nav><a id=mobile-nav-icon-link href=#><div id=mobile-nav-icon></div></a></div></div><div id=mobile-nav-dropdown><nav id=mobile-nav class="mobile-nav collapsed"><ul><li><a href=https://blog.qaware.de/ class=nav-item>Posts</a><ul><li><a href=https://blog.qaware.de/tags/ class=nav-item>Tags</a></li><li><a href=https://blog.qaware.de/posts/ class=nav-item>Archive</a></li></ul></li><li><a href=https://blog.qaware.de/ class=nav-item>Resources</a><ul><li><a href=https://www.github.com/qaware>GitHub</a></li><li><a href=https://de.slideshare.net/QAware>SlideShare</a></li><li><a href=https://www.youtube.com/user/QAwareGmbH>YouTube</a></li><li><a href=https://www.meetup.com/de-DE/Cloud-Native-Night>Meetup Mainz</a></li><li><a href=https://www.meetup.com/de-DE/cloud-native-muc/>Meetup Munich</a></li></ul></li><li><a href=https://www.qaware.de class=nav-item>Company</a><ul><li><a href=https://www.qaware.de>Website</a></li><li><a href=https://twitter.com/qaware>Twitter</a></li><li><a href=http://www.linkedin.com/company/qaware-gmbh>Linkedin</a></li><li><a href=http://www.xing.com/companies/qawaregmbh>Xing</a></li><li><a href=http://www.kununu.com/qaware>Kununu</a></li></ul></li><li><a href=https://www.qaware.de/kontakt class=nav-item>Contact</a></li></ul></nav></div></header><main><div class='wrap mt-4 post'><div><p class='post_date pale'>04. September 2023</p><h1 class=post_title>Don't Crack Under Pressure: Java Microservices and the Battle for Stability Under High Load</h1><p class=pale>by <a href=https://github.com/s-macke>Sebastian Macke</a> | 3509 words | ~17 min read</p><p><a class=post_tag href=/tags/java/>java</a>
<a class=post_tag href=/tags/web-framework/>web framework</a>
<a class=post_tag href=/tags/rest/>rest</a>
<a class=post_tag href=/tags/services/>services</a>
<a class=post_tag href=/tags/thread/>thread</a>
<a class=post_tag href=/tags/queue/>queue</a></p><div class=post_body><div class=post_inner><img src=https://blog.qaware.de/images/java-service-queues/connections.png alt=java-service-queues/connections.png class='post_thumbnail mt-1'><p>In recent years, I have been working for a large, well-established corporation with an extensive
IT ecosystem that spans several decades, including various infrastructure, software, and cloud environments,
with Java being the prominent language. Maintaining seamless operations and ensuring 24/7 availability
of all these systems is an immense challenge.</p><p>As site reliability engineer, I have frequently dealt with outages. Although there
could be countless reasons for outages, one technical issue that I find particularly bothersome is <em>high load</em> in Java services
and how to fail over safely. Especially when there is no ressource shortage at all.</p><p>This article is aimed at those who want to improve the reliability of their Java-based web application services
and those interested in gaining insights into load testing their services.</p><h1 id=a-simple-java-microservice>A simple Java Microservice</h1><p>Let&rsquo;s try an experiment together. Take a Web Application Java Framework. Any framework will do. <a href=https://spring.io/projects/spring-boot>Spring Boot</a> ? Ok.</p><p>We&rsquo;ll stick to a basic &ldquo;hello world&rdquo; example without any special configuration, just using plain Spring Boot.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Java data-lang=Java><span class=line><span class=cl>    <span class=nd>@GetMapping</span><span class=o>(</span><span class=s>&#34;/hello&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=n>String</span> <span class=nf>hello</span><span class=o>()</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s>&#34;Hello world&#34;</span><span class=o>;</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span></code></pre></td></tr></table></div></div><p>This code is very simple and just returns the string &ldquo;Hello world&rdquo;. We can easily perform a performance test on this using the load test tool <a href=https://github.com/s-macke/SlapperX>SlapperX</a>.</p><p>This test runs on the same machine as the service and sends 5000 requests per second.</p><style>.animated:hover{cursor:pointer}</style><img src=/images/java-service-queues/sb_0s_5000req_play.svg onclick='flipAnimation(this,"/images/java-service-queues/sb_0s_5000req_play.svg","/images/java-service-queues/sb_0s_5000req.svg")' class=animated>
<script>function flipAnimation(e,t,n){e.src.endsWith(n)?e.src=t:e.src=n}</script><p>The success rate is 100%, and the result always has a status code of 200. Even with such a high number of requests, the average response time for each request is less than 1ms.</p><h1 id=adding-a-blocking-action>Adding a blocking action</h1><p>Now, let&rsquo;s discuss a more realistic situation. Typically, a request involves additional actions like authentication, caching, file system access, database queries, and other backend calls.
These actions delay the current request until the result is ready.</p><p>It can take anywhere from a few milliseconds to several seconds, depending on the complexity and specific scenarios. In some cases, a request
may take up to dozens of seconds to get a response. While this is not ideal for the user, it is generally acceptable.
After all, we don&rsquo;t have the resources of giants like Google or Amazon to optimize every single request to its full potential.</p><p>To simulate a blocking action, we can simply add a <em>sleep</em> command to our code.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>    @GetMapping(&#34;/hello&#34;)
</span></span><span class=line><span class=cl>    public String hello() {
</span></span><span class=line><span class=cl>        Thread.sleep(1000); // Sleep for 1 second        
</span></span><span class=line><span class=cl>        return &#34;Hello world&#34;;
</span></span><span class=line><span class=cl>    }
</span></span></code></pre></td></tr></table></div></div><p>Now, the &ldquo;Hello world&rdquo; response will only be sent after a 1-second delay.</p><p>For our performance test, we&rsquo;ll limit it to 200 requests per second.</p><style>.animated:hover{cursor:pointer}</style><img src=/images/java-service-queues/sb_1s_200req_play.svg onclick='flipAnimation(this,"/images/java-service-queues/sb_1s_200req_play.svg","/images/java-service-queues/sb_1s_200req.svg")' class=animated>
<script>function flipAnimation(e,t,n){e.src.endsWith(n)?e.src=t:e.src=n}</script><p>The results are what we expected. On average, each request takes exactly 1 second. Additionally, the number of in-flight requests consistently stays around 200.
In-flight requests refer to those requests that have been sent but haven&rsquo;t received a response yet.</p><h1 id=what-happens-under-high-load>What happens under high load?</h1><p>Let us make a small change and call the service with 250 requests per second. That is just 50 requests per second more than in the previous example.</p><style>.animated:hover{cursor:pointer}</style><img src=/images/java-service-queues/sb_1s_250req_play.svg onclick='flipAnimation(this,"/images/java-service-queues/sb_1s_250req_play.svg","/images/java-service-queues/sb_1s_250req.svg")' class=animated>
<script>function flipAnimation(e,t,n){e.src.endsWith(n)?e.src=t:e.src=n}</script><p>It doesn&rsquo;t look good. Just seconds after starting the calls, the average response time increases significantly.
Within a minute, the in-flight requests skyrocket, and the average response time reaches 10 seconds.
The load test was set to have a 10-second timeout. No successful requests are made anymore.</p><p>We can play around with the parameters, such as increasing the sleep time to 5 seconds.</p><style>.animated:hover{cursor:pointer}</style><img src=/images/java-service-queues/sb_5s_250req_play.svg onclick='flipAnimation(this,"/images/java-service-queues/sb_5s_250req_play.svg","/images/java-service-queues/sb_5s_250req.svg")' class=animated>
<script>function flipAnimation(e,t,n){e.src.endsWith(n)?e.src=t:e.src=n}</script><p>In this case, the service completely fails in less than 10 seconds. A configured liveness probe would not work anymore and would result in a timeout.
Even after stopping the load test, the service remains unusable. Eventually, after several seconds, minutes, or even hours, the service starts to respond normally again.</p><p>So far, every Java framework I&rsquo;ve encountered behaves like this. However, the threshold varies for each framework.</p><h1 id=what-is-happening>What is happening?</h1><p>We might have reached a certain limit, but which one? First, let&rsquo;s check the complete log output of the service during its run:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  .   ____          _            __ _ _
</span></span><span class=line><span class=cl> /\\ / ___&#39;_ __ _ _(_)_ __  __ _ \ \ \ \
</span></span><span class=line><span class=cl>( ( )\___ | &#39;_ | &#39;_| | &#39;_ \/ _` | \ \ \ \
</span></span><span class=line><span class=cl> \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
</span></span><span class=line><span class=cl>  &#39;  |____| .__|_| |_|_| |_\__, | / / / /
</span></span><span class=line><span class=cl> =========|_|==============|___/=/_/_/_/
</span></span><span class=line><span class=cl> :: Spring Boot ::                (v2.7.5)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2023-06-18 16:33:45.966  INFO 21785 --- [           main] c.example.restdemo.RestdemoApplication   : Starting RestdemoApplication using Java 17.0.7 on $$$$ with PID 21785 (/home/user/spring_boot/restdemo/build/classes/java/main started by user in /home/user/spring_boot/restdemo)
</span></span><span class=line><span class=cl>2023-06-18 16:33:45.969  INFO 21785 --- [           main] c.example.restdemo.RestdemoApplication   : No active profile set, falling back to 1 default profile: &#34;default&#34;
</span></span><span class=line><span class=cl>2023-06-18 16:33:46.750  INFO 21785 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
</span></span><span class=line><span class=cl>2023-06-18 16:33:46.756  INFO 21785 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
</span></span><span class=line><span class=cl>2023-06-18 16:33:46.757  INFO 21785 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.68]
</span></span><span class=line><span class=cl>2023-06-18 16:33:46.824  INFO 21785 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
</span></span><span class=line><span class=cl>2023-06-18 16:33:46.825  INFO 21785 --- [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 798 ms
</span></span><span class=line><span class=cl>2023-06-18 16:33:47.211  INFO 21785 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 9 endpoint(s) beneath base path &#39;/actuator&#39;
</span></span><span class=line><span class=cl>2023-06-18 16:33:47.258  INFO 21785 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path &#39;&#39;
</span></span><span class=line><span class=cl>2023-06-18 16:33:47.271  INFO 21785 --- [           main] c.example.restdemo.RestdemoApplication   : Started RestdemoApplication in 1.596 seconds (JVM running for 1.846)
</span></span></code></pre></td></tr></table></div></div><p>The log output doesn&rsquo;t indicate any issues, and there&rsquo;s nothing in the DEBUG or TRACING log levels either.</p><p>Now, let&rsquo;s examine the server&rsquo;s hardware metrics: CPU performance, memory usage, and network throughput:</p><img src=/images/java-service-queues/metrics.png alt><p>The CPU is idle, network traffic is minimal, and RAM usage is slowly increasing but still low. Clearly, the hardware isn&rsquo;t causing the problem.</p><p>So, what&rsquo;s taking up time? Let&rsquo;s look at the tracing output. Every framework allows us to log tracing data, showing how long each request takes:</p><img src=/images/java-service-queues/tracing.png alt><p>In this tracing output, I&rsquo;ve added a gateway that also logs tracing data. The service still
believes each request takes exactly one second. Only the gateway metrics in relation to the service tracing reveal an issue in the form of a gap in the tracing data.</p><p>One final test: let&rsquo;s measure the actual duration of the request:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Java data-lang=Java><span class=line><span class=cl>    <span class=kd>private</span> <span class=kt>int</span> <span class=n>counter</span> <span class=o>=</span> <span class=n>0</span><span class=o>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@GetMapping</span><span class=o>(</span><span class=s>&#34;/hello&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=n>String</span> <span class=nf>hello</span><span class=o>()</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=kt>long</span> <span class=n>startTime</span> <span class=o>=</span> <span class=n>System</span><span class=o>.</span><span class=na>nanoTime</span><span class=o>();</span>
</span></span><span class=line><span class=cl>        <span class=n>Thread</span><span class=o>.</span><span class=na>sleep</span><span class=o>(</span><span class=n>1000</span><span class=o>);</span> <span class=c1>// Sleep for 1 second        
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=kt>long</span> <span class=n>stopTime</span> <span class=o>=</span> <span class=n>System</span><span class=o>.</span><span class=na>nanoTime</span><span class=o>();</span>
</span></span><span class=line><span class=cl>        <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>printf</span><span class=o>(</span><span class=s>&#34;Request No. %5d, Duration=%fs\n&#34;</span><span class=o>,</span> <span class=n>counter</span><span class=o>,</span> <span class=o>(</span><span class=n>stopTime</span> <span class=o>-</span> <span class=n>startTime</span><span class=o>)/</span><span class=n>1e9</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=n>counter</span><span class=o>++;</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s>&#34;Hello world&#34;</span><span class=o>;</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span></code></pre></td></tr></table></div></div><p>The output is</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>Request No.  2092, Duration=1.000083s
</span></span><span class=line><span class=cl>Request No.  2093, Duration=1.000103s
</span></span><span class=line><span class=cl>Request No.  2094, Duration=1.000093s
</span></span><span class=line><span class=cl>Request No.  2095, Duration=1.000156s
</span></span><span class=line><span class=cl>Request No.  2096, Duration=1.000094s
</span></span><span class=line><span class=cl>Request No.  2097, Duration=1.000084s
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>The request consistently takes one second. Even worse, the request number continues to increase even after stopping the load test for several minutes.
Calls sent minutes ago are still being processed even if the caller has long disconnected.</p><h1 id=recap>Recap</h1><p>To summarize:</p><p>We have written a tiny service with a simulated blocking operation and analyzed the response during a high request scenario.</p><ul><li>The service becomes unresponsive and is practically down.</li><li>There is no log output indicating a problem.</li><li>No hardware limitations are present.</li><li>Tracing doesn&rsquo;t reveal any issues. All requests are completed successfully.</li><li>For this reason, no alarms are triggered that directly monitor the service.</li><li>Calls continue to be executed and results are discarded even if the caller disconnects.</li></ul><style>.note{background-color:rgba(0,0,0,5%);margin-top:2em;margin-bottom:2em;padding:.125em 1em;border-left-width:4px;border-left-style:solid;border-color:var(--theme)!important}</style><div class=note><p>This is the default behaviour of Java microservices under high load conditions!</p></div><p>In real-life situations, such scenarios can arise easily. For instance, a backend system might
take a second longer due to maintenance or a malfunctioning node. One problematic backend system can cause your entire service to fail.</p><p>But, the problems don&rsquo;t end there. Users sending requests can also create high load conditions.
However, this doesn&rsquo;t apply to all endpoints. An example is an endpoint with a large return size, like 5MB:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Java data-lang=Java><span class=line><span class=cl>    <span class=n>String</span> <span class=n>returnString</span> <span class=o>=</span> <span class=k>new</span> <span class=n>String</span><span class=o>(</span><span class=k>new</span> <span class=kt>byte</span><span class=o>[</span><span class=n>5000000</span><span class=o>]);</span> <span class=c1>// 5 MB
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nd>@GetMapping</span><span class=o>(</span><span class=s>&#34;/hello&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=n>String</span> <span class=nf>hello</span><span class=o>()</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>returnString</span><span class=o>;</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span></code></pre></td></tr></table></div></div><p>In a test, we request the 5MB output at 10 requests per second.
At the 10 second mark, another program is launched to download the 5MB file 200 times at a speed
of 0 bytes per second. This second program stops after an additional 10 seconds.</p><style>.animated:hover{cursor:pointer}</style><img src=/images/java-service-queues/sb_5MB_play.svg onclick='flipAnimation(this,"/images/java-service-queues/sb_5MB_play.svg","/images/java-service-queues/sb_5MB.svg")' class=animated>
<script>function flipAnimation(e,t,n){e.src.endsWith(n)?e.src=t:e.src=n}</script><p>Since the returned value is larger than the internal buffers, the request remains active until the download is complete.
The service becomes immediately overwhelmed and unresponsive. Yes, that is all it needs to kill the service.
To attack a service and cause a denial of service can be easy.</p><h1 id=thread-pools-and-unbounded-request-queues>Thread Pools and Unbounded Request Queues</h1><p>The undesireable behavior occurs due to the way thread pools work in Java. The concept is straightforward and can be seen in this image:</p><img src=/images/java-service-queues/threadpools.png alt><p>The <a href=https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executors.html#newFixedThreadPool-int->fixed thread pool</a> documentation states:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>public static ExecutorService newFixedThreadPool(int nThreads)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Creates a thread pool that reuses a fixed number of threads operating off a shared
</span></span><span class=line><span class=cl>unbounded queue. At any point, at most nThreads threads will be active processing
</span></span><span class=line><span class=cl>tasks. If additional tasks are submitted when all threads are active, they will
</span></span><span class=line><span class=cl>wait in the queue until a thread is available.
</span></span></code></pre></td></tr></table></div></div><p>Each request uses one worker thread from start to finish. Spring Boot sets the default thread pool size at 200.
If the thread pool is full, the task is placed in a first in/first out queue.
However, this queue is <em>unbounded</em>, which is the main problem here.
Each request could wait a long time in the queue, making the service unusable.
The client connection status doesn&rsquo;t matter at this time as the task is already in the queue and is handled when there is a free worker thread.</p><p>So high load in Java Services can be defined as when the maximum number of parallel requests is reached.
This is typically not related to CPU, RAM, or network limitations.</p><p>Horizontal scaling fixes the high load problems. With tools like Kubernetes, we made it simple: <em>Just add more pods</em>.
It works, and your services run well again. However, is using more hardware and throwing money
to the problem the real solution?</p><h1 id=manage-your-queues>Manage your queues</h1><p>The solution is straightforward: Either increase worker threads or limit your queue size.</p><p>First, let&rsquo;s consider worker threads. Should we increase their number? Yes, we can do that.
However, remember that these threads are managed by the kernel, which is a shared resource
and responsible for the stability of your system. Overburdening the kernel with thread organization tasks is not recommended.
Have you ever heard of a <a href=https://en.wikipedia.org/wiki/Fork_bomb>fork bomb</a>?</p><p>Unfortunately, I have not found any information on a reasonable maximum capacity for the kernel.
Under laboratory conditions, it can handle 10,000 threads without any problem.
However, I am not sure about its capacity in a shared Kubernetes cluster or in a 24/7 scenario.
Server operating systems can also impose limits on the maximum number of threads.
For example, some Linux server distributions set the default limit to a low number, such as 512.</p><p>In any case, it is impossible to predict the optimal number of worker threads for every scenario.
This makes it a parameter that we want to eliminate in the long term (see Reactive and Virtual Threads below).</p><p>Now let&rsquo;s consider the queue. Should we limit its size? <em>Yes, definitely</em>. Reasonable values can be found in the book:</p><img src=/images/java-service-queues/sre_book.jpg alt><p>In their <em>Queue Management</em> chapter they suggest:</p><ul><li>If the request rate and latency is constant: No queue</li><li>If the request rate is fairly static: 50% or less of the thread pool size</li><li>For bursty loads: Choose a number based on average number of threads in use and the processing time of each request and the size and frequency of bursts.</li></ul><p>That are reasonable suggestions. Unbounded queues are not mentioned at all. So the best default value is zero or 50% of the thread pool size.</p><p>The exact opposite recommendation I&rsquo;ve come across is in the documentation of the <a href=https://quarkus.io/>Quarkus</a> framework:
<img src=/images/java-service-queues/quarkus_queue_suggestion.png alt></p><p>The discrepancy between Site Reliability Engineers and the author of the Java Framework documentation is just 0 vs. infinite.
Also no description of the parameter is given.</p><p>You might think that web frameworks would have reasonable default settings
in place and provide guidance for configuring services for production use.
Ideally, every service developer would follow these best practices.
Well, the existence of this article suggests that neither is the case.</p><h1 id=improving-the-spring-boot-configuration>Improving the Spring Boot configuration</h1><p>Here&rsquo;s what we want to achieve:</p><ul><li>The service should always be up, running, and responsive.</li><li>If the maximum number of requests is reached, the service should log this issue.</li><li>The service should stop further requests with an appropriate error.</li></ul><h2 id=tomcat-server>Tomcat Server</h2><p>Spring Boot provides three parameters for modifying the behavior of the built-in <a href=https://tomcat.apache.org/>Tomcat</a> server.
You can easily change the number of threads with a property like <code>server.tomcat.threads.max=5000</code>.</p><p>However the documentation doesn&rsquo;t mention the queue. Instead, it offers two alternative parameters:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>server.tomcat.max-connections
</span></span><span class=line><span class=cl>server.tomcat.accept-count
</span></span></code></pre></td></tr></table></div></div><p>These parameters can somewhat address high load issues as connections are loosely related to
requests and can be controlled by both the client and server.</p><p>However, these connection parameters are not appropriate to control the service.
A connection can have different meanings based on the protocol and implementation used.</p><ul><li>HTTP/1.1: One request per connection at the same time. Keep alive feature can keep a connection alive without a request.</li><li>HTTP/2: Multiplexing allows multiple parallel requests per connection. However, because of <a href=https://en.wikipedia.org/wiki/Head-of-line_blocking>Head-of-line-blocking</a>, this feature might not be used extensively.</li><li>HTTP/3: The connection is no longer handled by the kernel, but your application. Efficient multiplexing allows for separate streams within one connection. Only one connection necessary.</li></ul><p>These variants between the implementations and protocols make these connection parameters unpredictable.</p><p>Because of the lack to controle the queue I gave this article a developer of Spring Boot for review and as result, a new parameter will be introduced:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>server.tomcat.threads.max-queue-capacity
</span></span></code></pre></td></tr></table></div></div><style>.note{background-color:rgba(0,0,0,5%);margin-top:2em;margin-bottom:2em;padding:.125em 1em;border-left-width:4px;border-left-style:solid;border-color:var(--theme)!important}</style><div class=note><p>Until this parameter is implemented, the lack of control over server internals makes the default server engine in Spring Boot unsuitable for production environments.</p></div><h2 id=jetty-server>Jetty Server</h2><p>But Spring Boot allows using another server instead of Tomcat: <a href=https://www.eclipse.org/jetty/>Jetty</a>.</p><p>Switching to Jetty makes a big difference.</p><style>.animated:hover{cursor:pointer}</style><img src=/images/java-service-queues/sb_jetty_1s_250req_play.svg onclick='flipAnimation(this,"/images/java-service-queues/sb_jetty_1s_250req_play.svg","/images/java-service-queues/sb_jetty_1s_250req.svg")' class=animated>
<script>function flipAnimation(e,t,n){e.src.endsWith(n)?e.src=t:e.src=n}</script><p>Though the timeout issue still isn&rsquo;t solved, the server remains usable, and we get a mix of timeouts and successful calls.
Jetty&rsquo;s queue is implemented obviously differently and more reasonably.</p><p>We can now change the queue size from unbounded to 1 via the parameter <code>server.jetty.threads.max-queue-capacity=1</code>.</p><style>.animated:hover{cursor:pointer}</style><img src=/images/java-service-queues/sb_jetty_1s_250req_q1_play.svg onclick='flipAnimation(this,"/images/java-service-queues/sb_jetty_1s_250req_q1_play.svg","/images/java-service-queues/sb_jetty_1s_250req_q1.svg")' class=animated>
<script>function flipAnimation(e,t,n){e.src.endsWith(n)?e.src=t:e.src=n}</script><p>The service no longer allows requests to be queued and remains responsive under all conditions.
Additionally, we now see an error in the logs, which makes monitoring easier.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>2023-06-11 17:46:49.310  WARN 29714 --- [tp466319810-168] o.e.jetty.util.thread.QueuedThreadPool   : QueuedThreadPool[qtp466319810]@1bcb79c2{STARTED,8&lt;=200&lt;=200,i=178,r=-1,q=0}[ReservedTh
</span></span><span class=line><span class=cl>readExecutor@29fa40c9{reserved=8/12,pending=0}] rejected org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@79496273
</span></span><span class=line><span class=cl>2023-06-11 17:46:49.310  WARN 29714 --- [qtp466319810-79] o.e.jetty.util.thread.QueuedThreadPool   : QueuedThreadPool[qtp466319810]@1bcb79c2{STARTED,8&lt;=200&lt;=200,i=178,r=-1,q=0}[ReservedTh
</span></span><span class=line><span class=cl>readExecutor@29fa40c9{reserved=5/12,pending=0}] rejected org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@af086f5
</span></span><span class=line><span class=cl>2023-06-11 17:46:49.310  WARN 29714 --- [qtp466319810-31] o.e.jetty.util.thread.QueuedThreadPool   : QueuedThreadPool[qtp466319810]@1bcb79c2{STARTED,8&lt;=200&lt;=200,i=178,r=-1,q=0}[ReservedTh
</span></span><span class=line><span class=cl>readExecutor@29fa40c9{reserved=5/12,pending=0}] rejected org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@71038c20
</span></span><span class=line><span class=cl>2023-06-11 17:46:49.310  WARN 29714 --- [qtp466319810-37] o.e.jetty.util.thread.QueuedThreadPool   : QueuedThreadPool[qtp466319810]@1bcb79c2{STARTED,8&lt;=200&lt;=200,i=178,r=-1,q=0}[ReservedTh
</span></span><span class=line><span class=cl>readExecutor@29fa40c9{reserved=5/12,pending=0}] rejected org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@242e0902
</span></span><span class=line><span class=cl>2023-06-11 17:46:49.310  WARN 29714 --- [qtp466319810-19] o.e.jetty.util.thread.QueuedThreadPool   : QueuedThreadPool[qtp466319810]@1bcb79c2{STARTED,8&lt;=200&lt;=200,i=178,r=-1,q=0}[ReservedTh
</span></span><span class=line><span class=cl>readExecutor@29fa40c9{reserved=5/12,pending=0}] rejected org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@6950a041
</span></span><span class=line><span class=cl>2023-06-11 17:46:49.310  WARN 29714 --- [tp466319810-168] o.e.jetty.util.thread.QueuedThreadPool   : QueuedThreadPool[qtp466319810]@1bcb79c2{STARTED,8&lt;=200&lt;=200,i=177,r=-1,q=0}[ReservedTh
</span></span><span class=line><span class=cl>readExecutor@29fa40c9{reserved=5/12,pending=0}] rejected org.eclipse.jetty.io.ManagedSelector$DestroyEndPoint@a68223f
</span></span></code></pre></td></tr></table></div></div><p>However, the service only responds with an abrupt disconnect, not an error message for the client. This issue cannot be easily
fixed in Java and requires a complete change in the internal workings, as explained in the Reactive chapter.</p><p>The framework <a href=https://quarkus.io/>Quarkus</a> has addressed this problem and returns actually an error code when the queue is limited.</p><style>.animated:hover{cursor:pointer}</style><img src=/images/java-service-queues/quarkus_1s_250req_q1_play.svg onclick='flipAnimation(this,"/images/java-service-queues/quarkus_1s_250req_q1_play.svg","/images/java-service-queues/quarkus_1s_250req_q1.svg")' class=animated>
<script>function flipAnimation(e,t,n){e.src.endsWith(n)?e.src=t:e.src=n}</script><p>The <code>500 Internal Server Error</code> error code can be changed to a more reasonable <code>503 Service Unavailable</code> error.</p><p>This is probably the best-case scenario for Java services currently. The service remains responsive, and when worker threads are fully occupied, it returns an error code.</p><p>But there is more.</p><h1 id=the-importance-of-circuit-breakers>The importance of Circuit Breakers</h1><p>Once you understand the behaviour of Java Micro Services under high load you understand the need for circuit breakers in such frameworks.</p><p>Circuit breakers monitor error states and contain the logic to prevent future failures. They usually achieve this by not running the problematic code for a certain period of time.</p><p>In our case they can be used</p><ul><li>to protect the backend for being bombarded with more and more requests, which fill up their queues.</li><li>to prevent our service to reach the one-thread-per-request limit.</li><li>to give the user faster feedback about the failure state.</li></ul><p>In this case, a circuit breaker can be employed when a backend stops responding (Timeout exception).
It prevents sending too many requests to an overloaded backend. This way, the backend can recover and function properly again.</p><p>However, managing circuit breakers can be challenging. A poorly configured or misunderstood circuit breaker might be even more harmful than not having one at all.
The default of a circuit breaker is usually to trigger on every error state unless the status code is 2xx or 3xx.</p><p>Here is a small list of possible errors and how to handle them in general if they are dominant in the response statistics.</p><ul><li>Connection Timeout or Connection Reset: The backend is not even running. No reason to call it. The circuit breaker can trigger.</li><li>Response Timeout: The backend can be overloaded. Trigger the cricuit breaker.</li><li>SSL Handshake Error: One reason could be overloading, but also broken nodes. I would trigger the circuit breaker here.</li><li>Status Code 400 Bad Request: No reason to trigger. The Backend is working as expected.</li><li>Status Code 401 Unauthorized: No reason to trigger. The Backend is working as expected.</li><li>Status Code 500 Internal Server Error: Happens so often for so many reasons that this error state should be excluded from the cricuit breaker. Every non-handled error is mapped to this one.</li><li>Status Code 502 Bad Gateway: The backend is working as expected.</li><li>Status Code 503 Service Unavailable: Sounds like a good idea to trigger the circuit breaker here? But that means, that the server is already protecting itself. Usually no reason to protect it further.</li></ul><p>This short list depicts the difficulty to configure a circuit breaker. Better, the backend server is properly configured and protects itself.</p><h1 id=the-argument-for-reactive-programming>The argument for Reactive Programming</h1><p>One problem still exists: the limited number of worker threads and the lack of
correlation with CPU, RAM, and network usage.
Java&rsquo;s default operating mode uses blocking I/O, which causes the thread to
block entirely during an I/O operation. The same goes for the <em>Thread.sleep</em> function.</p><p>To manage blocking calls without using kernel threads, a solution is to utilize non-blocking I/O operations
provided by operating systems. This approach only blocks one thread for thousands of parallel I/O operations.
However, this involves creating an entirely new domain specific language within Java, which is a
challenging task that takes years of programming forcing reconsideration of control flow, loops, and exception handling.
This is referred to as Reactive programming in the Java world, and several frameworks are available for it.</p><p>The example below shows how a &ldquo;Hello World&rdquo; program would look in reactive programming:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Java data-lang=Java><span class=line><span class=cl><span class=kd>public</span> <span class=n>Mono</span><span class=o>&lt;</span><span class=n>ServerResponse</span><span class=o>&gt;</span> <span class=nf>hello</span><span class=o>(</span><span class=n>ServerRequest</span> <span class=n>request</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ServerResponse</span>
</span></span><span class=line><span class=cl>           <span class=o>.</span><span class=na>ok</span><span class=o>()</span>
</span></span><span class=line><span class=cl>           <span class=o>.</span><span class=na>body</span><span class=o>(</span><span class=n>BodyInserters</span><span class=o>.</span><span class=na>fromValue</span><span class=o>(</span><span class=s>&#34;Hello world&#34;</span><span class=o>))</span>
</span></span><span class=line><span class=cl>           <span class=o>.</span><span class=na>log</span><span class=o>(</span><span class=s>&#34;Request handled&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>           <span class=o>.</span><span class=na>delayElement</span><span class=o>(</span><span class=n>Duration</span><span class=o>.</span><span class=na>ofSeconds</span><span class=o>(</span><span class=n>1</span><span class=o>))</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></td></tr></table></div></div><p>Using anything outside of the provided dot-syntax can be risky, as it could result in blocking I/O operations.
Even an ordinary <em>System.out.println</em> line is problematic, because it could be a blocking I/O operation.
Also your entire code must be written in reactive language, and the same goes for all dependencies.
The style fights the design of Java and pays a high price in maintainability and observability.</p><p>But reactive programming for I/O-driven services will soon be replaced by a new Java feature: <em>Virtual Threads</em>.</p><h1 id=the-argument-for-virtual-threads>The argument for Virtual threads</h1><p>Reactive programming is not the only solution to address this issue.
For example, the Go programming language has &ldquo;Goroutines,&rdquo; which are essentially
virtual threads scheduled in user space. These lightweight threads can be parallelized
by the millions and do not interfere with the kernel and are only limited by CPU and RAM resources.
This eliminates the need to limit the number of threads.</p><p>With proper runtime support, there&rsquo;s no need to change the code you write.
A <em>Thread.sleep</em> function used in virtual threads puts the virtual thread to sleep, but not the kernel thread.
A win-win situation both for developers and reliability engineers.</p><p>This feature is coming soon with <a href=https://www.infoq.com/articles/java-virtual-threads/>Java 21</a>.
Framework developers have already pledged their support for virtual threads.</p><h1 id=conclusion>Conclusion</h1><p>Java remains the top language for Enterprise applications due to its superior ecosystem compared to other programming languages.</p><p>However, it still relies on an outdated threading model, which leads to the <em>one-kernel-thread-per-request</em> approach.
This works well under normal loads and is easy for frameworks to manage but can be difficult to configure and prone to unexpected failures, as highlighted in this article.</p><p>A potential solution to these issues is <em>Virtual Threads</em>, which could help overcome various
limitations and simplify the code. The idea of treating parallel running threads like function
calls is appealing, but it requires unlearning some long-standing Java programming habits.</p><p>In the meantime, while we await the introduction of virtual threads, it&rsquo;s important to remember one key suggestion:</p><style>.note{background-color:rgba(0,0,0,5%);margin-top:2em;margin-bottom:2em;padding:.125em 1em;border-left-width:4px;border-left-style:solid;border-color:var(--theme)!important}</style><div class=note><p>Limit your request queues!</p></div></div><div class='post_extra mb-2'><div class='share copy'></div><a href="http://twitter.com/share?text=Check out this post on the QAware Engineering Blog about Don%27t%20Crack%20Under%20Pressure%3a%20Java%20Microservices%20and%20the%20Battle%20for%20Stability%20Under%20High%20Load&url=https%3a%2f%2fblog.qaware.de%2fposts%2fjava-service-queues%2f&hashtags=Java%2cWebFramework%2cREST%2cServices%2cThread%2cQueue"><div class='share twitter'></div></a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3a%2f%2fblog.qaware.de%2fposts%2fjava-service-queues%2f"><div class='share linkedin'></div></a><a href="mailto:?subject=Don%27t%20Crack%20Under%20Pressure%3a%20Java%20Microservices%20and%20the%20Battle%20for%20Stability%20Under%20High%20Load&amp;body=Hi,%0D%0A%0D%0ACheck out this post on the QAware Engineering Blog: https%3a%2f%2fblog.qaware.de%2fposts%2fjava-service-queues%2f%0D%0A%0D%0ABest Regards"><div class='share email'></div></a></div><div></div></div></div></div><a href=https://blog.qaware.de/ class=post_nav><span class=post_next>The Latest Posts</span></a></main><footer><div class=footer-container><div class=short-link-area><div class=margin><div class=logo-qaware><a href=/><img src=/images/icons/logo-qaware-white.png alt=QAware width=195 height=43></a></div><div class=clr></div><div class=footer-links><a href=https://www.qaware.de/category/news/ class=foot-single-link>News</a>
<a href=https://www.qaware.de/kontakt/ class=foot-single-link>Kontakt</a><div class=footer-table><a href=https://www.qaware.de/impressum/ class="foot-single-link footer-table-cell">Legal Notice</a>&nbsp;|&nbsp;
<a href=https://www.qaware.de/datenschutz/ class="foot-single-link footer-table-cell">Privacy</a></div></div><nav class=nav-social><ul class=e-social id=c1375><li><a href=http://www.kununu.com/qaware title=Kununu target=_blank class="icon icon-kununu-outline"><span></span></a></li><li><a href=https://www.twitter.com/qaware title=Twitter target=_blank class="icon icon-twitter-outline"><span></span></a></li><li><a href=https://www.linkedin.com/company/qaware-gmbh title=LinkedIn target=_blank class="icon icon-linkedin-outline"><span></span></a></li><li><a href=https://github.com/qaware title=GitHub target=_blank class="icon icon-git-outline"><span></span></a></li><li><a href=https://www.slideshare.net/qaware title=SlideShare target=_blank class="icon icon-slideshare-outline"><span></span></a></li><li><a href=https://www.youtube.com/channel/UCmNf72xADnO57idipq9jvMg title=Youtube target=_blank class="icon icon-youtube-outline"><span></span></a></li></ul></nav><div class=clr></div></div></div><nav class="footer-nav nav-area"><ul class=margin><li><a href=https://www.qaware.de/leistungen/>Leistungen</a></li><li><a href=https://www.qaware.de/unternehmen/>Unternehmen</a></li><li><a href=https://www.qaware.de/karriere/>Karriere</a></li></ul></nav></div></footer><script src=https://blog.qaware.de/js/index.min.791bb653c336adab277d58e8a52b9e81250276bb14f8fced435ae89f02d3155ae233664425075d8cb7ef5444d08a4a2276ee6bf16082d57c12c85f010e25412a.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-45534590-1"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-45534590-1")</script></body></html>